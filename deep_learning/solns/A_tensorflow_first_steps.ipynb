{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"colab":{"name":"A_tensorflow_first_steps.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"dSRFiqZE2JDJ"},"source":["***\n","<h2> <u> First steps with tensorflow </u></h2>\n","\n","* In this part of the practical we will learn about `tensorflow` (tf) and `numpy` (np) and how the two packages can be used together.\n","* In particular, we learn about the difference between `tf.placeholder`, `tf.Variable` and `np.array`.\n","* In a nutshell the three can be defined as follows:\n","  * `np.array`: Holds arrays of data (usually numbers) of a certain type (often float32). \n","  * `tf.placeholder`: Is a node in a computational graph and does not have a fixed value. Rather they are like symbols in a maths equation until you plug in a value. Expressions of multiple placeholders (i.e. computational graphs) can only be evaluated in a `tf.Session`. \n","  * `tf.Variable`: Variables are a hybrid of the two above. They are like placeholders because they can be part of expressions with placeholders, but they also have a specific value. This value can be changed over time, this is why `tf.Variables` are usually used for parameters we want to optimise, such as network weights. \n"," \n","*** \n","Let's start by importing the two packages: "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-_Z4NOoz2JDQ","executionInfo":{"status":"ok","timestamp":1615912042803,"user_tz":-60,"elapsed":484,"user":{"displayName":"Ertunç Erdil","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMsoSHG0vnIOh_eNGTGwbaeoCOl-6inFuL6AA4=s64","userId":"03311864043264945628"}},"outputId":"ab4670ed-8204-43e8-e775-6c6e47c2c0ec"},"source":["import tensorflow as tf\n","import tensorflow.compat.v1 as tf\n","tf.disable_v2_behavior() \n","import numpy as np\n","import os"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EWvxK4ST2Z9m"},"source":["<h2> <u>Mount Google drive folder</u> </h2>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mB0VMGLx2dfl","executionInfo":{"status":"ok","timestamp":1615911863620,"user_tz":-60,"elapsed":19421,"user":{"displayName":"Ertunç Erdil","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMsoSHG0vnIOh_eNGTGwbaeoCOl-6inFuL6AA4=s64","userId":"03311864043264945628"}},"outputId":"c92306cd-f928-4fd9-d7d7-79a8738d97fe"},"source":["# Mount Google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bghtL17I2lMD","executionInfo":{"status":"ok","timestamp":1615911878036,"user_tz":-60,"elapsed":519,"user":{"displayName":"Ertunç Erdil","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMsoSHG0vnIOh_eNGTGwbaeoCOl-6inFuL6AA4=s64","userId":"03311864043264945628"}},"outputId":"6e6d1614-2948-4b02-b2ae-87291eaba2c6"},"source":["cd /content/drive/My Drive/ML_workshop"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/ML_workshop\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RTQL_Ewf2opY","executionInfo":{"status":"ok","timestamp":1615911884185,"user_tz":-60,"elapsed":565,"user":{"displayName":"Ertunç Erdil","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMsoSHG0vnIOh_eNGTGwbaeoCOl-6inFuL6AA4=s64","userId":"03311864043264945628"}},"outputId":"da7a3aed-a791-4825-fba6-3d338f0a380c"},"source":["ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[0m\u001b[01;34mdeep_learning\u001b[0m/  \u001b[01;34mmachine_learning\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zrsnz6hx2JDR"},"source":["***\n","<h3> <u> Placeholders </u></h3>\n","\n","Let's create two placeholders `x_pl` and `y_pl` and formulate an expression combining the two. \n","\n","`tf.placeholder` takes the datatype as mandatory input. Optionally, you can also specify it's `shape` and give it a `name`. A known shape can be useful for more complicated expressions and will reduce bugs. Similarly, giving it a name makes debugging easier.\n","\n","Try defining the following function `f_pl`: \n","\n","$ f(x,y) = x^2 + y^2 $\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FK2kOxmX2JDR","executionInfo":{"status":"ok","timestamp":1615912047950,"user_tz":-60,"elapsed":473,"user":{"displayName":"Ertunç Erdil","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMsoSHG0vnIOh_eNGTGwbaeoCOl-6inFuL6AA4=s64","userId":"03311864043264945628"}},"outputId":"432c2608-68fe-4eec-d0f3-3293864cd8a3"},"source":["x_pl = tf.placeholder(tf.float32, name='x')\n","y_pl = tf.placeholder(tf.float32, name='y')\n","\n","### TO DO 1 ####\n","# f_pl = x_pl**2 + y_pl**2\n","#######################\n","\n","print(x_pl)\n","print(y_pl)\n","print(f_pl)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tensor(\"x:0\", dtype=float32)\n","Tensor(\"y:0\", dtype=float32)\n","Tensor(\"add:0\", dtype=float32)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dlBc0T-V2JDS"},"source":["***\n","**What is a tensor?:** Tensors are [loosely speaking](https://physics.stackexchange.com/questions/20437/are-matrices-and-second-rank-tensors-the-same-thing) generalisations of matrices (2D) to other dimensions (ND). When working with images in deep learning one often works with 4D arrays of the form [batch_size, image_size_x, image_size_y, n_color_channels]. In tensorflow all Variables and placeholders are called tensors. \n","\n","***\n","As mentioned earlier, this expression can only be evaluated inside a `tf.Session`. Sessions have a function called `run`, \n","which we can use to evaluate expressions. In order to evaluate `f_pl`, we need to define values for `x_pl` and `y_pl`. \n","This is done using the `feed_dict` argument, as in the example below.\n","\n","Note that the `feed_dict` needs to be a [python dictionary](https://docs.python.org/2/tutorial/datastructures.html#dictionaries), which has the synatx: `{key1: value1, key2: value2, ...}`."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aSJDYmX32JDS","executionInfo":{"status":"ok","timestamp":1615912057406,"user_tz":-60,"elapsed":2099,"user":{"displayName":"Ertunç Erdil","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMsoSHG0vnIOh_eNGTGwbaeoCOl-6inFuL6AA4=s64","userId":"03311864043264945628"}},"outputId":"829e94c6-ad67-4d64-d527-6e0bbf2b659f"},"source":["with tf.Session() as sess:\n","    \n","    f_evaluated = sess.run(f_pl, feed_dict={x_pl: 1, y_pl: 2})\n","\n","print('The value of f evaluated at the given values is: %f' % f_evaluated)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The value of f evaluated at the given values is: 5.000000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3qb08nH52JDS"},"source":["Take good note of the above syntax. We will be using `sess.run(...)` with values fed through a `feed_dict` a lot throughout this tutorial. \n","\n","We can do many things with placeholders that one can also do with algebraic expressions. As an example the function `tf.gradients(a,b)` can be used to calculate the derivative of `a` w.r.t. `b`. In the cell below, use this `tf.gradients` function to implement an expression for: $ \\frac{\\partial f}{\\partial x} $"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sljWQ97B2JDS","executionInfo":{"status":"ok","timestamp":1615912071418,"user_tz":-60,"elapsed":498,"user":{"displayName":"Ertunç Erdil","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMsoSHG0vnIOh_eNGTGwbaeoCOl-6inFuL6AA4=s64","userId":"03311864043264945628"}},"outputId":"fab574ff-b1a5-4c58-9a55-e693025fae41"},"source":["# compute gradients of f_pl wrt x_pl\n","df_dx_pl = tf.gradients(f_pl, x_pl)\n","\n","with tf.Session() as sess:  # using the with statement we the Session is automatically closed at the end of\n","                            # expressions which are inside the with statement.     \n","    df_dx_evaluated = sess.run(df_dx_pl, feed_dict={x_pl: 1, y_pl: 2})\n","    \n","# The result returned in df_dx_evaluated is actually an array, so we need to extract the first, and only value using [0]\n","print('The gradient df_dx evaluated at the given values is: %f' % df_dx_evaluated[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The gradient df_dx evaluated at the given values is: 2.000000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fnpTald92JDT"},"source":["<h3> <u>Numpy arrays</u> </h3>\n","\n","* You are likely to have encountered numpy arrays before.\n","* Here we create two sample arrays `a` and `b` and then show how to use them in a tensorflow expression. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W_zj03Su2JDT","executionInfo":{"status":"ok","timestamp":1615912075768,"user_tz":-60,"elapsed":471,"user":{"displayName":"Ertunç Erdil","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMsoSHG0vnIOh_eNGTGwbaeoCOl-6inFuL6AA4=s64","userId":"03311864043264945628"}},"outputId":"4200ed9f-c6f1-4fef-d71f-d1baf6741189"},"source":["A = np.array([[1,2],[3,4]])\n","B = 4.2*np.ones((2,2))\n","\n","print('The two numpy arrays have values:')\n","print(A)\n","print(B)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The two numpy arrays have values:\n","[[1 2]\n"," [3 4]]\n","[[4.2 4.2]\n"," [4.2 4.2]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DpEjEqBZ2JDT"},"source":["Fortunately, working with `np.arrays` is no different from working with scalars. Since we didn't specify a shape for `x_pl` and `y_pl` above, we can now simply use them again assuming they are 2x2 arrays. \n","\n","`tf.matmul(x,y)` is the tensorflow function used for matrix multiplication. Below, implement expressions for \n"," - $g(X,Y) = XY$, and\n"," - $\\tfrac{\\partial g}{\\partial X}$  \n"," \n","Note that the usual multiplication symbol (`*`) will lead to an element wise matrix multiplication instead. For the proper matrix multiplication `tf.matmul` needs to be used. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NMdi40Ww2JDU","executionInfo":{"status":"ok","timestamp":1615912167490,"user_tz":-60,"elapsed":780,"user":{"displayName":"Ertunç Erdil","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMsoSHG0vnIOh_eNGTGwbaeoCOl-6inFuL6AA4=s64","userId":"03311864043264945628"}},"outputId":"8a1ca671-0241-48b2-e9f0-70adae926acd"},"source":["### TO DO 2 ####\n","# g_pl = tf.matmul(x_pl, y_pl)\n","# dg_dx_pl = tf.gradients(g_pl, x_pl)\n","###############################\n","\n","with tf.Session() as sess:\n","    \n","    # Note that sess.run can also be used to evaluate multiple expressions at once\n","    g_evaluated, dg_dx_evaluated = sess.run([g_pl, dg_dx_pl], feed_dict={x_pl: A, y_pl: B})\n","    \n","print('Function g(.) evaluated:')\n","print(g_evaluated)\n","\n","print('Function dg/dx evaluated:')\n","print(dg_dx_evaluated[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Function g(.) evaluated:\n","[[12.599999 12.599999]\n"," [29.399998 29.399998]]\n","Function dg/dx evaluated:\n","[[8.4 8.4]\n"," [8.4 8.4]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"X3zsuFgx2JDU"},"source":["### Shared variables \n","\n","Shared variables are symbolic variables that have a persistent value, as well. They are a sort of hybrid between numpy arrays and placeholders. However, Variables need to be initialised *within a session* before they can be used. To this end, first, a tensorflow init operation has to be defined, and then executed with `sess.run(...)`. \n","\n","Note that when evaluating a Variable, there is no need to feed it a value using `feed_dict` because it already has a value. In the example below use the `sess.run` function to run the `init_op`.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e5uz6xcR2JDU","executionInfo":{"status":"ok","timestamp":1615912172666,"user_tz":-60,"elapsed":580,"user":{"displayName":"Ertunç Erdil","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMsoSHG0vnIOh_eNGTGwbaeoCOl-6inFuL6AA4=s64","userId":"03311864043264945628"}},"outputId":"299b981d-801a-4bd0-aabb-060b3edbc7d6"},"source":["i_var = tf.Variable(0.0)\n","init_op = tf.global_variables_initializer()  # operation to initialise all tf.Variables in the scope\n","\n","with tf.Session() as sess:\n","    \n","    sess.run(init_op)  # init_op needs to be executed once before i_var can be used. \n","    \n","    i_evaluated = sess.run(i_var)  # No need for a feed_dict here, as i_var does not depend on the value of any placeholder\n","    \n","print('The value of i_var is: %f' % i_evaluated)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The value of i_var is: 0.000000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"y41vxqRr2JDV"},"source":["Nothing too surprising here.\n","\n","Because Variables have persistent values (within the context of a tf.Session), they are usually used for the parameters that are optimised in the learning process (e.g. the network weights and biases). \n","\n","We can for instance, define an operation that increments the value of `i_var` each time you run it. "]},{"cell_type":"code","metadata":{"id":"JTQbjZSH2JDV"},"source":["increment_op = tf.assign(i_var, i_var + 1)\n","\n","sess = tf.Session()  # Here we don't use the with statement, because we want the Session to stay active\n","\n","sess.run(init_op)  # Note that we need to run this again because the session from above is closed again."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qnbzpd-f2JDV"},"source":["**Evaluate the following cell multiple times.**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZnRkKzB92JDW","executionInfo":{"status":"ok","timestamp":1615912178907,"user_tz":-60,"elapsed":553,"user":{"displayName":"Ertunç Erdil","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMsoSHG0vnIOh_eNGTGwbaeoCOl-6inFuL6AA4=s64","userId":"03311864043264945628"}},"outputId":"c5654cf6-0b08-4b67-d579-a4ea122eba97"},"source":["# run the increment operation.\n","sess.run(increment_op)    \n","i_evaluated = sess.run(i_var)\n","print('The value of i_var is: %f' % i_evaluated)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The value of i_var is: 1.000000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VijXWFz22JDW"},"source":["Lastly, Variables can be combined with placeholders in expressions. Try writing an expression for $ x^i $ (for a scalar x) using the Variable `i_var` defined above and evaluate it in a session. And evaluate it for a range of x from 0 to 4. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l-9eOmIA2JDW","executionInfo":{"status":"ok","timestamp":1615912312320,"user_tz":-60,"elapsed":662,"user":{"displayName":"Ertunç Erdil","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhMsoSHG0vnIOh_eNGTGwbaeoCOl-6inFuL6AA4=s64","userId":"03311864043264945628"}},"outputId":"a2d2053c-52de-46e2-b2f9-602428a97786"},"source":["### TO DO 3 ####\n","power_pl = x_pl**i_var\n","######################\n","\n","for x in range(5):\n","    \n","    ### IMPLEMENT THIS ###\n","    # power_evaluated = sess.run(power_pl, feed_dict={x_pl: x})  # implement this\n","    # use the tf.Session to evaluate the power_pl expression above\n","    # power_evaluated = ...\n","    ######################\n","    \n","    print(' - %.2f^i = %.2f' % (x, power_evaluated))"],"execution_count":null,"outputs":[{"output_type":"stream","text":[" - 0.00^i = 0.00\n"," - 1.00^i = 1.00\n"," - 2.00^i = 2.00\n"," - 3.00^i = 3.00\n"," - 4.00^i = 4.00\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"M2emrI412JDW"},"source":["Lastly, because a `tf.Session()` may own resources, such as the variable we defined, it is important to release these resources when they are no longer required. Since we didn't use the `with` statement here, we need to invoke the `close()` method to do this."]},{"cell_type":"code","metadata":{"id":"sMEG0sPT2JDW"},"source":["sess.close()"],"execution_count":null,"outputs":[]}]}